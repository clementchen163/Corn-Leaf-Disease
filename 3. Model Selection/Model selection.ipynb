{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662f6353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, roc_curve, roc_auc_score, accuracy_score, recall_score, precision_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from model_select_func import save_model, load_model, record_results, avg_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e58ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123) # set random seed for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8db971",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR') # hide some warning messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94a266",
   "metadata": {},
   "source": [
    "#### Load Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a0ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_split_data_path='../0. Project Data/Original Split Data'\n",
    "reshaped_and_padded_data_path='../0. Project Data/Reshaped zero-padded and split data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181cb73d",
   "metadata": {},
   "source": [
    "#### Image Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcb7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original data parameters\n",
    "org_batch_size = 32\n",
    "org_img_height = 180\n",
    "org_img_width = 180\n",
    "org_img_channels = 3\n",
    "\n",
    "# padded image parameters\n",
    "padded_batch_size = 32\n",
    "padded_img_height = 256\n",
    "padded_img_width = 256\n",
    "padded_img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06ab7f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 843 files belonging to 4 classes.\n",
      "Found 843 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# tf.data dataset of original test data\n",
    "org_test_ds = image_dataset_from_directory(\n",
    "    original_split_data_path + '/test',\n",
    "    image_size=(org_img_width, org_img_height),\n",
    "    batch_size=org_batch_size,\n",
    "    shuffle=False,)\n",
    "# tf.data dataset of padded test data\n",
    "padded_test_ds = image_dataset_from_directory(\n",
    "    reshaped_and_padded_data_path + '/test',\n",
    "    image_size=(padded_img_width, padded_img_height),\n",
    "    batch_size=padded_batch_size,\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f78fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model 1-Original Data',\n",
       " 'Model 2-Zero-padded Data Model',\n",
       " 'Model 3-Zero-padded Data Transfer Learning Model',\n",
       " 'Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/1',\n",
       " 'Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/2',\n",
       " 'Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/3',\n",
       " 'Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/4',\n",
       " 'Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/5']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir=['Model 1-Original Data', 'Model 2-Zero-padded Data Model',\n",
    "           'Model 3-Zero-padded Data Transfer Learning Model']+[\n",
    "    'Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/' + str(i+1) for i in range(5)]\n",
    "model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b6e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Directories</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1-Original Data</td>\n",
       "      <td>Base CNN Org Data</td>\n",
       "      <td>Org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2-Zero-padded Data Model</td>\n",
       "      <td>Base CNN Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3-Zero-padded Data Transfer Learning Model</td>\n",
       "      <td>Transfer Learning Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Models 4.x-Transfer Learning Hyperparameter Tu...</td>\n",
       "      <td>Hypermodel1 Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Models 4.x-Transfer Learning Hyperparameter Tu...</td>\n",
       "      <td>Hypermodel2 Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Models 4.x-Transfer Learning Hyperparameter Tu...</td>\n",
       "      <td>Hypermodel3 Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Models 4.x-Transfer Learning Hyperparameter Tu...</td>\n",
       "      <td>Hypermodel4 Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Models 4.x-Transfer Learning Hyperparameter Tu...</td>\n",
       "      <td>Hypermodel5 Zero-Pad</td>\n",
       "      <td>Zero-Pad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Model Directories   \n",
       "0                              Model 1-Original Data  \\\n",
       "1                     Model 2-Zero-padded Data Model   \n",
       "2   Model 3-Zero-padded Data Transfer Learning Model   \n",
       "3  Models 4.x-Transfer Learning Hyperparameter Tu...   \n",
       "4  Models 4.x-Transfer Learning Hyperparameter Tu...   \n",
       "5  Models 4.x-Transfer Learning Hyperparameter Tu...   \n",
       "6  Models 4.x-Transfer Learning Hyperparameter Tu...   \n",
       "7  Models 4.x-Transfer Learning Hyperparameter Tu...   \n",
       "\n",
       "                   Model Name   Dataset  \n",
       "0           Base CNN Org Data       Org  \n",
       "1           Base CNN Zero-Pad  Zero-Pad  \n",
       "2  Transfer Learning Zero-Pad  Zero-Pad  \n",
       "3        Hypermodel1 Zero-Pad  Zero-Pad  \n",
       "4        Hypermodel2 Zero-Pad  Zero-Pad  \n",
       "5        Hypermodel3 Zero-Pad  Zero-Pad  \n",
       "6        Hypermodel4 Zero-Pad  Zero-Pad  \n",
       "7        Hypermodel5 Zero-Pad  Zero-Pad  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['Base CNN Org Data', 'Base CNN Zero-Pad', 'Transfer Learning Zero-Pad',\n",
    "               'Hypermodel1 Zero-Pad', 'Hypermodel2 Zero-Pad', 'Hypermodel3 Zero-Pad', \n",
    "               'Hypermodel4 Zero-Pad', 'Hypermodel5 Zero-Pad']\n",
    "dataset = ['Org', 'Zero-Pad', 'Zero-Pad', 'Zero-Pad', 'Zero-Pad', 'Zero-Pad', 'Zero-Pad', 'Zero-Pad']\n",
    "model_dict = {'Model Directories':model_dir, 'Model Name':model_names, 'Dataset':dataset}\n",
    "model_frame=pd.DataFrame(model_dict)\n",
    "model_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea172a3",
   "metadata": {},
   "source": [
    "#### Score Models Using Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97814c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model 1-Original Data from disk\n",
      "27/27 [==============================] - 27s 210ms/step\n",
      "Loaded Model 2-Zero-padded Data Model from disk\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(record_results(load_model(row[\u001b[38;5;241m0\u001b[39m]), row[\u001b[38;5;241m1\u001b[39m], org_test_ds))\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m row[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZero-Pad\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrecord_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_test_ds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#break\u001b[39;00m\n\u001b[0;32m      9\u001b[0m results\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(scores, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1 score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\Documents\\Springboard\\Corn-Leaf-Disease\\3. Model Selection\\model_select_func.py:39\u001b[0m, in \u001b[0;36mrecord_results\u001b[1;34m(model, model_name, dataset)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_results\u001b[39m(model, model_name, dataset):\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    Records metrics for given classifier\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    ---Parameters---\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    list of metrics for classifier \u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     y_pred_probas \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     y_pred_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_pred_probas, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m     y_true_labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:986\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    985\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[0;32m    990\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "for index, row in model_frame.iterrows():\n",
    "    if row[2]=='Org':\n",
    "        scores.append(record_results(load_model(row[0]), row[1], org_test_ds))\n",
    "    elif row[2]=='Zero-Pad':\n",
    "        scores.append(record_results(load_model(row[0]), row[1], padded_test_ds))\n",
    "    #break\n",
    "    \n",
    "results= pd.DataFrame(scores, columns=['Model Name', 'f1 score', 'test_acc', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc681395",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051404d",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10921414",
   "metadata": {},
   "source": [
    "Based on the scoring chart above, we can see that the Hypermodel 1 using Zero-Padded data outperforms all other models in all metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f757560",
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperModel1=load_model('Models 4.x-Transfer Learning Hyperparameter Tuning Zero-padded Data Model/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6063b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperModel1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff90d910",
   "metadata": {},
   "source": [
    "This model was built using the convolutional base of the pre-trained VGG16 model ontop of which a densely connected layer, a drop out layer and classification layer reside. The convolutional base consists of a conv, conv, pooling stacked pyramidial architecture as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b76a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    " weights='imagenet',\n",
    " include_top=False)\n",
    "conv_base.trainable = False # freeze weights\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c192b",
   "metadata": {},
   "source": [
    "The number of nodes in the densely connected layer as well as the dropout percentage were choosen empirically through hyperparameter tuning. The winning model had hyperparameters of 128  nodes in the densely connected layer and a dropout percentage of 50%. This model was then trained on zero-padded data before final evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32869f14",
   "metadata": {},
   "source": [
    "#### Confusion Matrix of Winning Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10527be",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = []\n",
    "for images, labels in padded_test_ds:\n",
    "    true_labels.extend(labels.numpy())\n",
    "y_pred_probas = HyperModel1.predict(padded_test_ds)\n",
    "y_pred_labels = np.argmax(y_pred_probas, axis = 1)\n",
    "cm=confusion_matrix(true_labels, y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31600730",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "disp=ConfusionMatrixDisplay(confusion_matrix= cm,\n",
    "                            display_labels=padded_test_ds.class_names)\n",
    "disp.plot(xticks_rotation= 13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a798940",
   "metadata": {},
   "source": [
    "From the confusion matrix of the test data, we can see that the majority of the misclassifications are between the disease classes of Blight, Common_Rust, and Gray_Leaf_Spot. Some of this could be due to misclassification of the true labels due to human error when constructing the dataset. \n",
    "\n",
    "The worse predicted class was Gray_Leaf_Spot with 22% of its images being misclassified as Blight and 3% being misclassified as Common_Rust. This is probably due to the class imbalance where there exists a 0.27, 0.31, 0.14, 0.28 proportion between the Blight, Common_Rust, Gray_Leaf_Spot, Healthy classes respectively. With Gray_Leaf_Spot having half as many instances as the other class, the model we created which optimized based on accuracy, didn't value misclassifying Gray_Leaf_Spot as much as the other classes. \n",
    "\n",
    "The true Healthy class instances were all predicted correctly with only 1 Blight image being misclassified as Healthy. This makes sense as we can see from the average class images shown below, there is a distinct visual separation between the Healthy and diseased classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_path = '../0. Project Data/Reshaped and zero-padded Data/'\n",
    "padded_dir = pathlib.Path(padded_path).with_suffix('')\n",
    "for class_ in ['Blight', 'Common_Rust', 'Gray_Leaf_Spot', 'Healthy']:\n",
    "    avg_image(class_, padded_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bca332",
   "metadata": {},
   "source": [
    "Let us see the Blight image that was misclassified as Healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'true_labels':true_labels, 'pred_labels':y_pred_labels}\n",
    "label_df = pd.DataFrame(label_dict)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image 154 was from the Blight class but misclassified as Healthy\n",
    "label_df[(label_df['true_labels']!=label_df['pred_labels']) & (label_df['pred_labels']==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=0\n",
    "for batch, labels in padded_test_ds:\n",
    "    for i in range(len(batch)):\n",
    "        if counter != 154: #\n",
    "            counter+=1\n",
    "            continue\n",
    "        counter+=1\n",
    "        # Convert the image tensor to numpy array\n",
    "        image_np = batch[i].numpy()\n",
    "        # Round due to bilinear interpolation\n",
    "        image_np = np.round(image_np).astype(int)\n",
    "        # Display the image using Matplotlib\n",
    "        plt.imshow(image_np)\n",
    "        plt.title(str(labels[i]))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c49d02e",
   "metadata": {},
   "source": [
    "The above Blight image being misclassified as Healthy is understandable; there are only a few slight miscolorations on the leaves while the majority of the surface area is a lush green."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494a87da",
   "metadata": {},
   "source": [
    "If our classification goal was simplified to identifying diseased vs healthy corn leaves, our current model would have 99.88% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73594c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
